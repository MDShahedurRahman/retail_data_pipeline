# Retail Sales Data Engineering Pipeline (PySpark)

A complete **Data Engineering Medallion Pipeline** project built using **PySpark**.  
This project demonstrates how raw retail sales data can be ingested from CSV, cleaned and transformed into Parquet format, modeled into a Star Schema, and queried for business insights.

It is designed as a **portfolio-quality backend data pipeline** that showcases real-world ETL workflows, Spark processing, and analytics-ready outputs.

---

## ğŸš€ Project Overview

Retail companies often receive large volumes of raw transactional data.  
This pipeline processes sales data through three structured layers:

- **Bronze Layer** â†’ Raw ingestion (CSV â†’ Parquet)
- **Silver Layer** â†’ Cleaned and enriched datasets
- **Gold Layer** â†’ Star Schema + analytics-ready fact/dimension tables

Finally, the pipeline runs **business queries** to generate insights such as:

- Top revenue categories
- Highest spending customers
- Revenue by city

---

## ğŸ— Architecture (Medallion Design)

```
Raw CSV Data
     â†“
Bronze Layer (Raw Parquet)
     â†“
Silver Layer (Clean + Enriched Parquet)
     â†“
Gold Layer (Star Schema Tables)
     â†“
Business Queries + Reports
```

---

## ğŸ“‚ Project Structure

```
retail_data_pipeline/
â”‚
â”œâ”€â”€ main.py
â”œâ”€â”€ config.py
â”œâ”€â”€ requirements.txt
â”‚
â”œâ”€â”€ data/
â”‚   â””â”€â”€ raw_sales.csv
â”‚
â”œâ”€â”€ jobs/
â”‚   â”œâ”€â”€ bronze_ingestion.py
â”‚   â”œâ”€â”€ silver_cleaning.py
â”‚   â”œâ”€â”€ gold_star_schema.py
â”‚   â””â”€â”€ business_queries.py
â”‚
â”œâ”€â”€ utils/
â”‚   â”œâ”€â”€ spark_session.py
â”‚   â”œâ”€â”€ schema_definitions.py
â”‚   â””â”€â”€ helpers.py
â”‚
â””â”€â”€ output/
    â”œâ”€â”€ bronze/
    â”œâ”€â”€ silver/
    â”œâ”€â”€ gold/
    â””â”€â”€ reports/
```

---

## ğŸ“Œ Data Source

The pipeline uses a sample retail dataset:

`data/raw_sales.csv`

Example:

```csv
order_id,customer_id,customer_name,product_id,product_name,category,quantity,unit_price,order_date,city
101,C001,John Smith,P001,Laptop,Electronics,1,1200,2025-01-10,New York
102,C002,Sarah Lee,P002,Headphones,Electronics,2,150,2025-01-11,Boston
```

---


## âš™ï¸ Technologies Used

- **Python**
- **PySpark**
- **Parquet Storage Format**
- **Medallion Architecture**
- **Star Schema Modeling**
- **Business Analytics Queries**

---

## ğŸš€ Pipeline Jobs

---

### ğŸ¥‰ Bronze Layer: Raw Ingestion

**File:** `jobs/bronze_ingestion.py`

- Reads raw CSV sales data
- Applies schema validation
- Writes raw Parquet output

Output:

```
output/bronze/
```

---

### ğŸ¥ˆ Silver Layer: Cleaning & Transformation

**File:** `jobs/silver_cleaning.py`

Key transformations:

- Remove duplicates
- Handle missing values
- Convert dates into proper format
- Add derived metric: `total_price`

Output:

```
output/silver/
```

---
